{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Simple Agent using LangChain and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to show you how to build a simple agent using [LangChain](https://www.langchain.com/), and [OpenAI](https://openai.com/). The code is based on the [\"Build an Agent\"](https://python.langchain.com/v0.2/docs/tutorials/agents/) LangChain tutorial, but with modifications to hit a custom API as part of the agent's tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "\n",
    "if not environ.get(\"OPENAI_API_KEY\"):\n",
    "    from getpass import getpass\n",
    "    environ[\"OPENAI_API_KEY\"] = getpass(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from random import choices\n",
    "from string import ascii_lowercase\n",
    "from typing import Literal\n",
    "\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.prebuilt import create_react_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI chat model (replace \"gpt-4o\" with your desired model)\n",
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the checkpoint saver\n",
    "checkpointer = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Vehicle:\n",
    "    brand: str\n",
    "    model: str\n",
    "    type_: Literal[\"truck\"] | Literal[\"suv\"] | Literal[\"sedan\"] | Literal[\"hatchback\"] | Literal[\"compact\"]\n",
    "    is_electric: bool\n",
    "    km_per_liter: int | None\n",
    "    range_in_km: int | None\n",
    "    seats: int\n",
    "    price: int\n",
    "\n",
    "@tool\n",
    "def lookup_vehicles(\n",
    "    brand: str | None = None,\n",
    "    model: str | None = None,\n",
    "    type_: str | None = None,\n",
    "    is_electric: bool | None = None\n",
    ") -> list[Vehicle]:\n",
    "    \"\"\"List vehicles based on their brand, model, type and whether it is electric\"\"\"\n",
    "    df = pd.read_csv(\"vehicles.csv\")\n",
    "\n",
    "    if brand is not None:\n",
    "        df = df[df.brand == brand]\n",
    "\n",
    "    if model is not None:\n",
    "        df = df[df.model == model]\n",
    "\n",
    "    if type_ is not None:\n",
    "        df = df[df.type_ == type_]\n",
    "\n",
    "    if is_electric is not None:\n",
    "        df = df[df.is_electric == is_electric]\n",
    "\n",
    "    return [Vehicle(**record) for record in df.to_dict(\"records\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tools\n",
    "tools = [lookup_vehicles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chat prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(\n",
    "        content=\"You are a virtual assistant named 'SimpleAgent'. You are an expert on cars.\"\n",
    "    ),\n",
    "    MessagesPlaceholder(\"messages\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "agent_executor = create_react_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    checkpointer=checkpointer,\n",
    "    messages_modifier=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Gradio interface\n",
    "def chat_interface_fn(\n",
    "    agent: Runnable,\n",
    "    message: str,\n",
    "    history: list[list[str]],  # We don't use the ChatInterface history\n",
    "    thread_id: str\n",
    "):\n",
    "    \"\"\"\n",
    "    ChatInterface fn argument. This is invoked everytime the\n",
    "    \"Submit\" button is pressed on the Gradio interface.\n",
    "    \"\"\"\n",
    "    response = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=message)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}},\n",
    "    )\n",
    "    return response[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=partial(chat_interface_fn, agent_executor),\n",
    "    additional_inputs=[\n",
    "        gr.Textbox(\"\".join(choices(ascii_lowercase, k=8)), label=\"Thread ID\"),\n",
    "    ],\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple-agent-langchain-openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
